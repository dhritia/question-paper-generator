{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YObCNXtr_J-"
      },
      "source": [
        "# Installing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WSlyy1u_9vA-"
      },
      "outputs": [],
      "source": [
        "!pip install https://github.com/pypa/pip/archive/master.zip\n",
        "!pip install --quiet gradio\n",
        "!pip install git+https://github.com/LIAAD/yake\n",
        "!pip install flashtext\n",
        "!pip install transformers\n",
        "!pip install nltk\n",
        "!python -m spacy download en\n",
        "!pip install spacy==2.1.3 --upgrade --force-reinstall\n",
        "!pip install pywsd==1.0.2\n",
        "!pip install -U wn==0.0.23\n",
        "!pip install bert-extractive-summarizer --upgrade --force-reinstall\n",
        "!pip install sentence-transformers==0.2.5.1\n",
        "!pip install benepar==0.1.2\n",
        "!pip install summa\n",
        "!pip install scipy\n",
        "!pip install transformers==2.6.0\n",
        "!pip install torch==1.4.0\n",
        "!pip install tensorflow==1.14.0\n",
        "!pip install markupsafe==2.0.1\n",
        "!pip install tabulate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iR6rMLaaM37X"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GsHYe5BIpd1A"
      },
      "source": [
        "# Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-bTE46mP-nYj"
      },
      "outputs": [],
      "source": [
        "import string\n",
        "import re\n",
        "import string\n",
        "import itertools\n",
        "import statistics\n",
        "import csv\n",
        "import os\n",
        "import torch\n",
        "import time\n",
        "import random\n",
        "import yake\n",
        "import transformers\n",
        "import benepar\n",
        "import scipy\n",
        "import gradio as gr\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('popular')\n",
        "from nltk import tokenize\n",
        "from nltk import pos_tag\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.corpus import wordnet as wn\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from nltk.tokenize import word_tokenize\n",
        "from statistics import mode\n",
        "from tabulate import tabulate\n",
        "from pywsd.similarity import max_similarity\n",
        "from pywsd.lesk import adapted_lesk\n",
        "from flashtext import KeywordProcessor\n",
        "from collections import namedtuple\n",
        "from tabulate import tabulate\n",
        "from torch.nn.functional import softmax\n",
        "from tqdm import tqdm\n",
        "from transformers import BertTokenizer\n",
        "from transformers import pipeline\n",
        "from summa.summarizer import summarize\n",
        "from string import punctuation\n",
        "benepar.download('benepar_en2')\n",
        "benepar_parser = benepar.Parser(\"benepar_en2\")\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "from sentence_transformers import SentenceTransformer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mH2S209Id5Xx"
      },
      "source": [
        "# Pre-Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IJz3Qgb7oSz7"
      },
      "outputs": [],
      "source": [
        "def tokenize_sentences(text):\n",
        "    sentences = sent_tokenize(text)\n",
        "    sentences = [sentence.strip() for sentence in sentences if len(sentence) > 20]\n",
        "    return sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aSDB9XDd9YBu"
      },
      "outputs": [],
      "source": [
        "def get_keywords(text):\n",
        "  lem = WordNetLemmatizer()\n",
        "  stoplist = list(string.punctuation)\n",
        "  stoplist += stopwords.words('english')\n",
        "  kw_extractor = yake.KeywordExtractor(lan='en', n=2, dedupFunc='0.9', top=50, stopwords=stoplist)\n",
        "  keywords = kw_extractor.extract_keywords(text)\n",
        "  res = [item for t in keywords for item in t]\n",
        "  keywords = [i for j, i in enumerate(res) if j % 2 == 0]\n",
        "  keywords_new = []\n",
        "  lemm = []\n",
        "  for k in keywords:\n",
        "    w = word_tokenize(k)\n",
        "    pos = pos_tag(w)\n",
        "    flag = 0\n",
        "    for i in range(len(pos)):\n",
        "      if pos[i][1]=='NN' or pos[i][1]=='NNS' or pos[i][1]=='NNP' or pos[i][1]=='NNPS':\n",
        "        continue\n",
        "      else:\n",
        "        flag = 1\n",
        "        break\n",
        "    if flag == 0:\n",
        "      if lem.lemmatize(k) not in lemm:\n",
        "        keywords_new.append(k)\n",
        "        lemm.append(lem.lemmatize(k))\n",
        "  return keywords_new"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tvjVX2dYWWNB"
      },
      "outputs": [],
      "source": [
        "def get_sentences_for_keyword(keywords, sentences):\n",
        "    keyword_processor = KeywordProcessor()\n",
        "    keyword_sentences = {}\n",
        "    for word in keywords:\n",
        "        keyword_sentences[word] = []\n",
        "        keyword_processor.add_keyword(word)\n",
        "    for sentence in sentences:\n",
        "        keywords_found = keyword_processor.extract_keywords(sentence)\n",
        "        for key in keywords_found:\n",
        "            keyword_sentences[key].append(sentence)\n",
        "    for key in keyword_sentences.keys():\n",
        "        values = keyword_sentences[key]\n",
        "        values = sorted(values, key=len, reverse=False)\n",
        "        keyword_sentences[key] = values\n",
        "    return keyword_sentences"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eoGYYFB1iym2"
      },
      "source": [
        "# True or False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7FAmUTWliyTl"
      },
      "outputs": [],
      "source": [
        "def preprocess(sentences):\n",
        "  output = []\n",
        "  for sent in sentences:\n",
        "      single_quotes_present = len(re.findall(r\"['][\\w\\s.:;,!?\\\\-]+[']\",sent))>0\n",
        "      double_quotes_present = len(re.findall(r'[\"][\\w\\s.:;,!?\\\\-]+[\"]',sent))>0\n",
        "      question_present = \"?\" in sent\n",
        "      if single_quotes_present or double_quotes_present or question_present :\n",
        "          continue\n",
        "      else:\n",
        "          output.append(sent.strip(punctuation))\n",
        "  return output\n",
        "def get_candidate_sents(resolved_text, ratio=0.5): #change\n",
        "  candidate_sents = summarize(resolved_text, ratio=ratio)\n",
        "  candidate_sents_list = tokenize.sent_tokenize(candidate_sents)\n",
        "  candidate_sents_list = [re.split(r'[:;]+',x)[0] for x in candidate_sents_list ]\n",
        "  filtered_list_short_sentences = [sent for sent in candidate_sents_list if len(sent)<150] #change\n",
        "  return filtered_list_short_sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dPWEQrr36l8u"
      },
      "outputs": [],
      "source": [
        "def get_flattened(t):\n",
        "  sent_str_final = None\n",
        "  if t is not None:\n",
        "      sent_str = [\" \".join(x.leaves()) for x in list(t)]\n",
        "      sent_str_final = [\" \".join(sent_str)]\n",
        "      sent_str_final = sent_str_final[0]\n",
        "  return sent_str_final\n",
        "\n",
        "def get_termination_portion(main_string,sub_string):\n",
        "  combined_sub_string = sub_string.replace(\" \",\"\")\n",
        "  main_string_list = main_string.split()\n",
        "  last_index = len(main_string_list)\n",
        "  for i in range(last_index):\n",
        "      check_string_list = main_string_list[i:]\n",
        "      check_string = \"\".join(check_string_list)\n",
        "      check_string = check_string.replace(\" \",\"\")\n",
        "      if check_string == combined_sub_string:\n",
        "          return \" \".join(main_string_list[:i])\n",
        "  return None\n",
        "\n",
        "def get_right_most_VP_or_NP(parse_tree,last_NP = None,last_VP = None):\n",
        "  if len(parse_tree.leaves()) == 1:\n",
        "      return get_flattened(last_NP),get_flattened(last_VP)\n",
        "  last_subtree = parse_tree[-1]\n",
        "  if last_subtree.label() == \"NP\":\n",
        "      last_NP = last_subtree\n",
        "  elif last_subtree.label() == \"VP\":\n",
        "      last_VP = last_subtree\n",
        "  return get_right_most_VP_or_NP(last_subtree,last_NP,last_VP)\n",
        "\n",
        "def get_sentence_completions(key_sentences):\n",
        "  sentence_completion_dict = {}\n",
        "  for individual_sentence in key_sentences:\n",
        "      sentence = individual_sentence.rstrip('?:!.,;')\n",
        "      tree = benepar_parser.parse(sentence)\n",
        "      last_nounphrase, last_verbphrase =  get_right_most_VP_or_NP(tree)\n",
        "      phrases= []\n",
        "      if last_verbphrase is not None:\n",
        "          verbphrase_string = get_termination_portion(sentence,last_verbphrase)\n",
        "          phrases.append(verbphrase_string)\n",
        "      if last_nounphrase is not None:\n",
        "          nounphrase_string = get_termination_portion(sentence,last_nounphrase)\n",
        "          phrases.append(nounphrase_string)\n",
        "\n",
        "      longest_phrase =  sorted(phrases, key=len,reverse= True)\n",
        "      if len(longest_phrase) == 2:\n",
        "          first_sent_len = len(longest_phrase[0].split())\n",
        "          second_sentence_len = len(longest_phrase[1].split())\n",
        "          if (first_sent_len - second_sentence_len) > 4:\n",
        "              del longest_phrase[1]\n",
        "\n",
        "      if len(longest_phrase)>0:\n",
        "          sentence_completion_dict[sentence]=longest_phrase\n",
        "  return sentence_completion_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rJnAbzCu8FGQ"
      },
      "outputs": [],
      "source": [
        "def sort_by_similarity(original_sentence,generated_sentences_list):\n",
        "  model_BERT = SentenceTransformer('bert-base-nli-mean-tokens')\n",
        "  sentence_embeddings = model_BERT.encode(generated_sentences_list)\n",
        "  queries = [original_sentence]\n",
        "  query_embeddings = model_BERT.encode(queries)\n",
        "  number_top_matches = len(generated_sentences_list)\n",
        "  dissimilar_sentences = []\n",
        "  for query, query_embedding in zip(queries, query_embeddings):\n",
        "      distances = scipy.spatial.distance.cdist([query_embedding], sentence_embeddings, \"cosine\")[0]\n",
        "      results = zip(range(len(distances)), distances)\n",
        "      results = sorted(results, key=lambda x: x[1])\n",
        "      for idx, distance in reversed(results[0:number_top_matches]):\n",
        "          score = 1-distance\n",
        "          if score < 0.94: #change\n",
        "              dissimilar_sentences.append(generated_sentences_list[idx].strip())\n",
        "  sorted_dissimilar_sentences = sorted(dissimilar_sentences, key=len)\n",
        "  return sorted_dissimilar_sentences[:3]\n",
        "\n",
        "def generate_sentences(partial_sentence,full_sentence):\n",
        "  tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "  model = GPT2LMHeadModel.from_pretrained(\"gpt2\",pad_token_id=tokenizer.eos_token_id)\n",
        "  torch.manual_seed(7879)\n",
        "  input_ids = torch.tensor([tokenizer.encode(partial_sentence)])\n",
        "  maximum_length = len(partial_sentence.split())+80\n",
        "  sample_outputs = model.generate(\n",
        "      input_ids,\n",
        "      do_sample=True,\n",
        "      max_length=maximum_length,\n",
        "      top_p=0.95, # 0.85\n",
        "      top_k=50,   #0.30\n",
        "      repetition_penalty  = 10.0,\n",
        "      num_return_sequences=10\n",
        "  )\n",
        "  generated_sentences=[]\n",
        "  for i, sample_output in enumerate(sample_outputs):\n",
        "      decoded_sentences = tokenizer.decode(sample_output, skip_special_tokens=True)\n",
        "      decoded_sentences_list = tokenize.sent_tokenize(decoded_sentences)\n",
        "      generated_sentences.append(decoded_sentences_list[0])\n",
        "  top_3_sentences = sort_by_similarity(full_sentence,generated_sentences)\n",
        "  return top_3_sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vMAUkqWl6LMy"
      },
      "outputs": [],
      "source": [
        "def trueorfalse(text):\n",
        "  statements = preprocess(get_candidate_sents(text))\n",
        "  statement_dict = get_sentence_completions(statements)\n",
        "  i = 1\n",
        "  torf = '<p>State whether the following statements are True or False:<br><br>'\n",
        "  for key_sentence in statement_dict:\n",
        "    partial_sentences = statement_dict[key_sentence]\n",
        "    for partial_sent in partial_sentences:\n",
        "        false_sents = generate_sentences(partial_sent,key_sentence)\n",
        "    if random.random()<0.5:\n",
        "      torf += 'Q'+str(i)+') '+key_sentence+'<br>Answer: True<br><br>'\n",
        "    else:\n",
        "      torf += 'Q'+str(i)+') '+false_sents[0]+'<br>Answer: False<br><br>'\n",
        "    i = i+1\n",
        "  torf += '</p>'\n",
        "  return torf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2OvDVyWHuHSP"
      },
      "source": [
        "# MCQ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mj-SEG7FiXvd"
      },
      "outputs": [],
      "source": [
        "def get_distractors_wordnet(syn,word):\n",
        "    distractors=[]\n",
        "    word= word.lower()\n",
        "    orig_word = word\n",
        "    if len(word.split())>0:\n",
        "        word = word.replace(\" \",\"_\")\n",
        "    hypernym = syn.hypernyms()\n",
        "    if len(hypernym) == 0:\n",
        "        return distractors\n",
        "    for item in hypernym[0].hyponyms():\n",
        "        name = item.lemmas()[0].name()\n",
        "        if name == orig_word:\n",
        "            continue\n",
        "        name = name.replace(\"_\",\" \")\n",
        "        name = \" \".join(w.capitalize() for w in name.split())\n",
        "        if name is not None and name not in distractors:\n",
        "            distractors.append(name)\n",
        "    return distractors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GtckAn1JjwXp"
      },
      "outputs": [],
      "source": [
        "def get_wordsense(sent,word):\n",
        "    word= word.lower()\n",
        "    if len(word.split())>0:\n",
        "        word = word.replace(\" \",\"_\")\n",
        "    synsets = wn.synsets(word,'n')\n",
        "    if synsets:\n",
        "        #wup = max_similarity(sent, word, 'wup', pos='n')\n",
        "        adapted_lesk_output =  adapted_lesk(sent, word, pos='n')\n",
        "        #lowest_index = min (synsets.index(wup),synsets.index(adapted_lesk_output))\n",
        "        lowest_index = synsets.index(adapted_lesk_output)\n",
        "        return synsets[lowest_index]\n",
        "    else:\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FurOXu40uGjL"
      },
      "outputs": [],
      "source": [
        "def mcq(text):\n",
        "  model = summarizer = pipeline(\"summarization\")\n",
        "  result = model(text, min_length=60, max_length = 500)\n",
        "  summarized_text = result[0]['summary_text']\n",
        "  keywords = get_keywords(summarized_text)\n",
        "  filtered_keys=[]\n",
        "  for keyword in keywords:\n",
        "      if keyword.lower() in summarized_text.lower():\n",
        "          filtered_keys.append(keyword)\n",
        "  sentences = tokenize_sentences(summarized_text)\n",
        "  keyword_sentence_mapping = get_sentences_for_keyword(keywords, sentences)\n",
        "  key_distractor_list = {}\n",
        "  for keyword in keyword_sentence_mapping:\n",
        "    if keyword_sentence_mapping[keyword] == []:\n",
        "      continue\n",
        "    wordsense = get_wordsense(keyword_sentence_mapping[keyword][0],keyword)\n",
        "    if wordsense:\n",
        "        distractors = get_distractors_wordnet(wordsense,keyword)\n",
        "        if len(distractors) != 0:\n",
        "            key_distractor_list[keyword] = distractors\n",
        "  i = 1\n",
        "  mcq = '<p>Multiple Choice Questions:<br><br>'\n",
        "  for each in key_distractor_list:\n",
        "    sentence = keyword_sentence_mapping[each][0]\n",
        "    pattern = re.compile(each, re.IGNORECASE)\n",
        "    output = pattern.sub( \" _______ \", sentence)\n",
        "    mcq += str(i)+')'+output+'<br>'\n",
        "    choices = [each.capitalize()] + key_distractor_list[each]\n",
        "    top4choices = choices[:4]\n",
        "    random.shuffle(top4choices)\n",
        "    optionchoices = ['a','b','c','d']\n",
        "    for idx,choice in enumerate(top4choices):\n",
        "        mcq += optionchoices[idx]+\") \"+choice+'<br>'\n",
        "    mcq += 'Answer: '+each+'<br><br>'\n",
        "    i = i + 1\n",
        "  mcq += '</p>'\n",
        "  return mcq"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5_CNycnrcJf"
      },
      "source": [
        "# Match the following"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MNz0zFZzrXqN",
        "outputId": "b52182ff-ca82-4fc9-cf4b-bebbec521346"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/My Drive/bert_base-augmented-batch_size=128-lr=2e-5-max_gloss=6  is extracted already\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "bert_wsd_pytorch = \"/content/gdrive/My Drive/bert_base-augmented-batch_size=128-lr=2e-5-max_gloss=6.zip\"\n",
        "extract_directory = \"/content/gdrive/My Drive\"\n",
        "\n",
        "extracted_folder = bert_wsd_pytorch.replace(\".zip\",\"\")\n",
        "\n",
        "#  If unzipped folder exists don't unzip again.\n",
        "if not os.path.isdir(extracted_folder):\n",
        "  with zipfile.ZipFile(bert_wsd_pytorch, 'r') as zip_ref:\n",
        "      zip_ref.extractall(extract_directory)\n",
        "else:\n",
        "  print (extracted_folder,\" is extracted already\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EnmszaP9zSpe"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import math\n",
        "from transformers import BertModel, BertConfig, BertPreTrainedModel, BertTokenizer\n",
        "\n",
        "class BertWSD(BertPreTrainedModel):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "\n",
        "        self.bert = BertModel(config)\n",
        "        self.dropout = torch.nn.Dropout(config.hidden_dropout_prob)\n",
        "\n",
        "        self.ranking_linear = torch.nn.Linear(config.hidden_size, 1)\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "\n",
        "\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model_dir = \"/content/gdrive/My Drive/bert_base-augmented-batch_size=128-lr=2e-5-max_gloss=6\"\n",
        "\n",
        "\n",
        "model = BertWSD.from_pretrained(model_dir)\n",
        "tokenizer = BertTokenizer.from_pretrained(model_dir)\n",
        "# add new special token\n",
        "if '[TGT]' not in tokenizer.additional_special_tokens:\n",
        "    tokenizer.add_special_tokens({'additional_special_tokens': ['[TGT]']})\n",
        "    assert '[TGT]' in tokenizer.additional_special_tokens\n",
        "    model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "model.to(DEVICE)\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I0bWxo4vFUfH",
        "outputId": "5708e44b-d723-4161-85be-6781ad2d244b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "import os\n",
        "from collections import namedtuple\n",
        "\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "from nltk.corpus import wordnet as wn\n",
        "\n",
        "import torch\n",
        "import re\n",
        "import time\n",
        "import torch\n",
        "from tabulate import tabulate\n",
        "from torch.nn.functional import softmax\n",
        "from tqdm import tqdm\n",
        "from transformers import BertTokenizer\n",
        "def _create_features_from_records(records, max_seq_length, tokenizer, cls_token_at_end=False, pad_on_left=False,\n",
        "                                  cls_token='[CLS]', sep_token='[SEP]', pad_token=0,\n",
        "                                  sequence_a_segment_id=0, sequence_b_segment_id=1,\n",
        "                                  cls_token_segment_id=1, pad_token_segment_id=0,\n",
        "                                  mask_padding_with_zero=True, disable_progress_bar=False):\n",
        "    features = []\n",
        "    for record in tqdm(records, disable=disable_progress_bar):\n",
        "        tokens_a = tokenizer.tokenize(record.sentence)\n",
        "\n",
        "        sequences = [(gloss, 1 if i in record.targets else 0) for i, gloss in enumerate(record.glosses)]\n",
        "\n",
        "        pairs = []\n",
        "        for seq, label in sequences:\n",
        "            tokens_b = tokenizer.tokenize(seq)\n",
        "            _truncate_seq_pair(tokens_a, tokens_b, max_seq_length - 3)\n",
        "            tokens = tokens_a + [sep_token]\n",
        "            segment_ids = [sequence_a_segment_id] * len(tokens)\n",
        "\n",
        "            tokens += tokens_b + [sep_token]\n",
        "            segment_ids += [sequence_b_segment_id] * (len(tokens_b) + 1)\n",
        "\n",
        "            if cls_token_at_end:\n",
        "                tokens = tokens + [cls_token]\n",
        "                segment_ids = segment_ids + [cls_token_segment_id]\n",
        "            else:\n",
        "                tokens = [cls_token] + tokens\n",
        "                segment_ids = [cls_token_segment_id] + segment_ids\n",
        "\n",
        "            input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "            input_mask = [1 if mask_padding_with_zero else 0] * len(input_ids)\n",
        "            padding_length = max_seq_length - len(input_ids)\n",
        "            if pad_on_left:\n",
        "                input_ids = ([pad_token] * padding_length) + input_ids\n",
        "                input_mask = ([0 if mask_padding_with_zero else 1] * padding_length) + input_mask\n",
        "                segment_ids = ([pad_token_segment_id] * padding_length) + segment_ids\n",
        "            else:\n",
        "                input_ids = input_ids + ([pad_token] * padding_length)\n",
        "                input_mask = input_mask + ([0 if mask_padding_with_zero else 1] * padding_length)\n",
        "                segment_ids = segment_ids + ([pad_token_segment_id] * padding_length)\n",
        "            assert len(input_ids) == max_seq_length\n",
        "            assert len(input_mask) == max_seq_length\n",
        "            assert len(segment_ids) == max_seq_length\n",
        "            BertInput = namedtuple(\"BertInput\", [\"input_ids\", \"input_mask\", \"segment_ids\", \"label_id\"])\n",
        "            pairs.append(\n",
        "                BertInput(input_ids=input_ids, input_mask=input_mask, segment_ids=segment_ids, label_id=label)\n",
        "            )\n",
        "        features.append(pairs)\n",
        "    return features\n",
        "def _truncate_seq_pair(tokens_a, tokens_b, max_length):\n",
        "    while True:\n",
        "        total_length = len(tokens_a) + len(tokens_b)\n",
        "        if total_length <= max_length:\n",
        "            break\n",
        "        if len(tokens_a) > len(tokens_b):\n",
        "            tokens_a.pop()\n",
        "        else:\n",
        "            tokens_b.pop()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wJSpZRuOF-52"
      },
      "outputs": [],
      "source": [
        "def get_sense(sent):\n",
        "  re_result = re.search(r\"\\[TGT\\](.*)\\[TGT\\]\", sent)\n",
        "  if re_result is None:\n",
        "      print(\"\\nIncorrect input format. Please try again.\")\n",
        "  ambiguous_word = re_result.group(1).strip()\n",
        "  results = dict()\n",
        "  for i, synset in enumerate(set(wn.synsets(ambiguous_word))):\n",
        "      results[synset] =  synset.definition()\n",
        "  if len(results) ==0:\n",
        "    return None\n",
        "  sense_keys=[]\n",
        "  definitions=[]\n",
        "  for sense_key, definition in results.items():\n",
        "      sense_keys.append(sense_key)\n",
        "      definitions.append(definition)\n",
        "  GlossSelectionRecord = namedtuple(\"GlossSelectionRecord\", [\"guid\", \"sentence\", \"sense_keys\", \"glosses\", \"targets\"])\n",
        "  record = GlossSelectionRecord(\"test\", sent, sense_keys, definitions, [-1])\n",
        "  MAX_SEQ_LENGTH = 128\n",
        "  features = _create_features_from_records([record], MAX_SEQ_LENGTH, tokenizer,\n",
        "                                            cls_token=tokenizer.cls_token,\n",
        "                                            sep_token=tokenizer.sep_token,\n",
        "                                            cls_token_segment_id=1,\n",
        "                                            pad_token_segment_id=0,\n",
        "                                            disable_progress_bar=True)[0]\n",
        "  with torch.no_grad():\n",
        "      logits = torch.zeros(len(definitions), dtype=torch.double).to(DEVICE)\n",
        "      for i, bert_input in list(enumerate(features)):\n",
        "          logits[i] = model.ranking_linear(\n",
        "              model.bert(\n",
        "                  input_ids=torch.tensor(bert_input.input_ids, dtype=torch.long).unsqueeze(0).to(DEVICE),\n",
        "                  attention_mask=torch.tensor(bert_input.input_mask, dtype=torch.long).unsqueeze(0).to(DEVICE),\n",
        "                  token_type_ids=torch.tensor(bert_input.segment_ids, dtype=torch.long).unsqueeze(0).to(DEVICE)\n",
        "              )[1]\n",
        "          )\n",
        "      scores = softmax(logits, dim=0)\n",
        "      preds = (sorted(zip(sense_keys, definitions, scores), key=lambda x: x[-1], reverse=True))\n",
        "  sense = preds[0][0]\n",
        "  meaning = preds[0][1]\n",
        "  return sense"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v2aOpD1WASMl"
      },
      "outputs": [],
      "source": [
        "def matchthefollowing(text):\n",
        "  keyword_best_sense = {}\n",
        "  keywords = get_keywords(text)[:8]\n",
        "  sentences = tokenize_sentences(text)\n",
        "  keyword_sentence_mapping = get_sentences_for_keyword(keywords, sentences)\n",
        "  for keyword in  keyword_sentence_mapping:\n",
        "    try:\n",
        "      identified_synsets=set(wn.synsets(keyword))\n",
        "    except:\n",
        "      continue\n",
        "    top_3_sentences = keyword_sentence_mapping[keyword][:3]\n",
        "    best_senses=[]\n",
        "    for sent in top_3_sentences:\n",
        "      insensitive_keyword = re.compile(re.escape(keyword), re.IGNORECASE)\n",
        "      modified_sentence = insensitive_keyword.sub(\" [TGT] \"+keyword+\" [TGT] \", sent,count=1)\n",
        "      modified_sentence = \" \".join(modified_sentence.split())\n",
        "      best_sense = get_sense(modified_sentence)\n",
        "      best_senses.append(best_sense)\n",
        "    if best_senses==[]:\n",
        "      continue\n",
        "    best_sense = mode(best_senses)\n",
        "    if best_sense is not None:\n",
        "      defn = best_sense.definition()\n",
        "      keyword_best_sense [keyword] = defn\n",
        "  all_keywords= list(keyword_best_sense.keys())\n",
        "  all_definitions = list(keyword_best_sense.values())\n",
        "  matchthefollow = \"<p>Match the following:<br><br><table border=1><tr><th>Column A</th><th>Column B</th></tr>\"\n",
        "  all_d = list(keyword_best_sense.values())\n",
        "  random.shuffle(all_d)\n",
        "  ans = \"Answer:\"\n",
        "  i,c = 1,'a'\n",
        "  for key,defn in zip(all_keywords,all_d):\n",
        "    ans += str(i)+'-'+chr(all_definitions.index(defn)+97)+' '\n",
        "    matchthefollow += '<tr><td>'+str(i)+') '+key+'</td><td>'+c+') '+defn+'</td></tr>'\n",
        "    i += 1\n",
        "    c = chr(ord(c)+1)\n",
        "  matchthefollow += '</table><br>' + ans + '</p>'\n",
        "  return matchthefollow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pl5UsRdfrhJR"
      },
      "source": [
        "# Fill in the blanks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V8cZel5Wre2m"
      },
      "outputs": [],
      "source": [
        "def get_fill_in_the_blanks(text):\n",
        "    sentences = sent_tokenize(text)\n",
        "    keywords = get_keywords(text)\n",
        "    sentence_mapping = get_sentences_for_keyword(keywords, sentences)\n",
        "    out={\"title\":\"Fill in the blanks for these sentences with matching words at the top\"}\n",
        "    blank_sentences = []\n",
        "    processed = []\n",
        "    keys=[]\n",
        "    for key in sentence_mapping:\n",
        "        if len(sentence_mapping[key])>0:\n",
        "            sent = sentence_mapping[key][0]\n",
        "            insensitive_sent = re.compile(re.escape(key), re.IGNORECASE)\n",
        "            no_of_replacements =  len(re.findall(re.escape(key),sent,re.IGNORECASE))\n",
        "            line = insensitive_sent.sub(' _________ ', sent)\n",
        "            if (sentence_mapping[key][0] not in processed) and no_of_replacements<2:\n",
        "                blank_sentences.append(line)\n",
        "                processed.append(sentence_mapping[key][0])\n",
        "                keys.append(key)\n",
        "    out[\"sentences\"]=blank_sentences\n",
        "    out[\"keys\"]=keys\n",
        "    fib = \"<p>Fill in the blanks:<br><br>\"\n",
        "    i = 1\n",
        "    while i<len(out['sentences']):\n",
        "      fib += \"Q\"+str(i)+\": \"+out['sentences'][i-1]+\"<br>\"\n",
        "      fib += \"Answer: \"+out['keys'][i-1]+\"<br><br>\"\n",
        "      i += 1\n",
        "    fib += '</p>'\n",
        "    return fib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GE0R3Pi8B2n9"
      },
      "source": [
        "# UI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 640
        },
        "id": "2YQFXdM7vshl",
        "outputId": "598159f8-7958-430a-86da-54626e2d15c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set `debug=True` in `launch()`\n",
            "Running on public URL: https://20539.gradio.app\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting, check out Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7f35bee74390>"
            ],
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"900\"\n",
              "            height=\"500\"\n",
              "            src=\"https://20539.gradio.app\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "        ></iframe>\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<fastapi.applications.FastAPI at 0x7f35c7826c90>,\n",
              " 'http://127.0.0.1:7860/',\n",
              " 'https://20539.gradio.app')"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "def qna(text, questions):\n",
        "  output = ''\n",
        "  if 'MCQ' in questions:\n",
        "    output += mcq(text)\n",
        "  if 'True/False' in questions:\n",
        "    output += trueorfalse(text)\n",
        "  if 'Fill in the Blanks' in questions:\n",
        "    output += get_fill_in_the_blanks(text)\n",
        "  if 'Match the following' in questions:\n",
        "    output += matchthefollowing(text)\n",
        "  return output\n",
        "iface = gr.Interface(\n",
        "  qna,\n",
        "  [gr.inputs.Textbox(lines=10, placeholder=\"Enter text here\"),\n",
        "  gr.inputs.CheckboxGroup(['MCQ', 'True/False', 'Fill in the Blanks', 'Match the following'], label=\"Select the type of questions\"),],\n",
        "  outputs=gr.outputs.HTML(label=\"Question and Answers\"),\n",
        "  allow_screenshot=False,\n",
        "  allow_flagging=\"never\",\n",
        "  title=\"Question Paper Generator\",)\n",
        "iface.launch(debug=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CvsTz7g6rTQV"
      },
      "source": [
        "# Run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VXHRnZLjough"
      },
      "outputs": [],
      "source": [
        "text = \"\"\"There is a lot of volcanic activity at divergent plate boundaries in the oceans. For example, many undersea volcanoes are found along the Mid-Atlantic Ridge. This is a divergent plate boundary that runs north-south through the middle of the Atlantic Ocean. As tectonic plates pull away from each other at a divergent plate boundary, they create deep fissures, or cracks, in the crust. Molten rock, called magma, erupts through these cracks onto Earth’s surface. At the surface, the molten rock is called lava. It cools and hardens, forming rock. Divergent plate boundaries also occur in the continental crust. Volcanoes form at these boundaries, but less often than in ocean crust. That’s because continental crust is thicker than oceanic crust. This makes it more difficult for molten rock to push up through the crust. Many volcanoes form along convergent plate boundaries where one tectonic plate is pulled down beneath another at a subduction zone. The leading edge of the plate melts as it is pulled into the mantle, forming magma that erupts as volcanoes. When a line of volcanoes forms along a subduction zone, they make up a volcanic arc. The edges of the Pacific plate are long subduction zones lined with volcanoes. This is why the Pacific rim is called the “Pacific Ring of Fire.”\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WieJvbc4gJ_0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd014b4f-40f2-44e9-a3d0-4df8c5c42071"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<p>Fill in the blanks:<br><br>Q1:  _________  boundaries also occur in the continental crust.<br>Answer: divergent plate<br><br>Q2: The leading edge of the  _________  melts as it is pulled into the mantle, forming magma that erupts as volcanoes.<br>Answer: plate<br><br>Q3:  _________  form at these boundaries, but less often than in ocean crust.<br>Answer: volcanoes<br><br>Q4: Many volcanoes form along convergent  _________  where one tectonic plate is pulled down beneath another at a subduction zone.<br>Answer: plate boundaries<br><br>Q5: This is a divergent plate boundary that runs north-south through the middle of the  _________ .<br>Answer: Atlantic Ocean<br><br>Q6: At the surface, the  _________  is called lava.<br>Answer: Molten rock<br><br>Q7: It cools and hardens, forming  _________ .<br>Answer: rock<br><br>Q8: The edges of the Pacific plate are long  _________  zones lined with volcanoes.<br>Answer: subduction<br><br>Q9: For example, many undersea volcanoes are found along the Mid-Atlantic  _________ .<br>Answer: Ridge<br><br>Q10: This is why the Pacific rim is called the “ _________  of Fire.”<br>Answer: Pacific Ring<br><br>Q11: There is a  _________  of volcanic activity at divergent plate boundaries in the oceans.<br>Answer: lot<br><br>Q12: When a line of volcanoes forms along a  _________ , they make up a volcanic arc.<br>Answer: subduction zone<br><br>Q13: Molten rock, called magma, erupts through these  _________  onto Earth’s surface.<br>Answer: cracks<br><br></p>\n"
          ]
        }
      ],
      "source": [
        "#Fill in the blanks\n",
        "fill_in_the_blanks = get_fill_in_the_blanks(text)\n",
        "print(fill_in_the_blanks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "68dVZCAOgAnJ"
      },
      "outputs": [],
      "source": [
        "#Match the following\n",
        "mf = matchthefollowing(text)\n",
        "print(mf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_RYRnh41w8dS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5834d5ee-8918-4410-f855-fc704c974e6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<p>Multiple Choice Questions:<br><br>1)For example, many undersea volcanoes are found along the Mid-Atlantic  _______ .<br>a) Girder<br>b) Box Beam<br>c) Ridge<br>d) Cantilever<br>Answer: Ridge<br><br>2)That’s because continental  _______  is thicker than oceanic  _______ .<br>a) Abruptness<br>b) Boorishness<br>c) Contempt<br>d) Crust<br>Answer: crust<br><br>3)There is a  _______  of volcanic activity at divergent plate boundaries in the oceans.<br>a) Catch<br>b) Charm<br>c) Commemorative<br>d) Lot<br>Answer: lot<br><br>4)There is a lot of volcanic  _______  at divergent plate boundaries in the oceans.<br>a) Chelation<br>b) Decrease<br>c) Activity<br>d) Dealignment<br>Answer: activity<br><br>5)Volcanoes form at these  _______ , but less often than in ocean crust.<br>a) Boundaries<br>b) Area<br>c) Depth<br>d) Coverage<br>Answer: boundaries<br><br>6) _______  form at these boundaries, but less often than in ocean crust.<br>a) Ben<br>b) Seamount<br>c) Volcanoes<br>d) Alp<br>Answer: volcanoes<br><br>7)For  _______ , many undersea volcanoes are found along the Mid-Atlantic Ridge.<br>a) Antitype<br>b) Abstractionism<br>c) Example<br>d) Appearance<br>Answer: example<br><br>8)There is a lot of volcanic activity at divergent plate boundaries in the  _______ .<br>a) Battalion<br>b) Barrels<br>c) Oceans<br>d) Batch<br>Answer: oceans<br><br>9)For example, many undersea volcanoes are  _______  along the Mid-Atlantic Ridge.<br>a) Double Time<br>b) Found<br>c) Combat Pay<br>d) Half-pay<br>Answer: found<br><br>10)Volcanoes  _______  at these boundaries, but less often than in ocean crust.<br>a) Form<br>b) Character<br>c) Ballast<br>d) Cheerfulness<br>Answer: form<br><br></p>\n"
          ]
        }
      ],
      "source": [
        "#MCQ\n",
        "print(mcq(text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gt9chw-K968W"
      },
      "outputs": [],
      "source": [
        "#True or False\n",
        "print(trueorfalse(text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bP5QzwEWp09z"
      },
      "outputs": [],
      "source": [
        "text = \"The Greek historian knew what he was talking about. The Nile river fed Egyptian civilization for hundreds of years. The longest river the Nile is 4,160 miles long—the world’s longest river. It begins near the equator in Africa and flows north to the Mediterranean Sea. In the south the Nile churns with cataracts. A cataract is a waterfall. Near the sea the Nile branches into a delta. A delta is an area near a river’s mouth where the water deposits fine soil called silt. In the delta, the Nile divides into many streams. The river is called the upper Nile in the south and the lower Nile in the north. For centuries, heavy rains in Ethiopia caused the Nile to flood every summer. The floods deposited rich soil along the Nile’s shores. This soil was fertile, which means it was good for growing crops. Unlike the Tigris and Euphrates, the Nile River flooded at the same time every year, so farmers could predict when to plant their crops. Red Land, Black Land The ancient Egyptians lived in narrow bands of land on each side of the Nile. They called this region the black land because of the fertile soil that the floods deposited. The red land was the barren desert beyond the fertile region. Weather in Egypt was almost always the same. Eight months of the year were sunny and hot. The four months of winter were sunny but cooler. Most of the region received only an inch of rain a year. The parts of Egypt not near the Nile were a desert. Isolation The harsh desert acted as a barrier to keep out enemies. The Mediterranean coast was swampy and lacked good harbors. For these reasons, early Egyptians stayed close to home. Each year, Egyptian farmers watched for white birds called ibises, which flew up from the south. When the birds arrived, the annual flood waters would soon follow. After the waters drained away, farmers could plant seeds in the fertile soil. Agricultural Techniques By about 2400 B.C., farmers used technology to expand their farmland. Working together, they dug irrigation canals that carried river water to dry areas. Then they used a tool called a shaduf to spread the water across the fields. These innovative, or new, techniques gave them more farmland. Egyptian Crops Ancient Egyptians grew a large variety of foods. They were the first to grind wheat into flour and to mix the flour with yeast and water to make dough rise into bread. They grew vegetables such as lettuce, radishes, asparagus, and cucumbers. Fruits included dates, figs, grapes, and watermelons. Egyptians also grew the materials for their clothes. They were the first to weave fibers from flax plants into a fabric called linen. Lightweight linen cloth was perfect for hot Egyptian days. Men wore linen wraps around their waists. Women wore loose, sleeveless dresses. Egyptians also wove marsh grasses into sandals. Egyptian houses Egyptians built houses using bricks made of mud from the Nile mixed with chopped straw. They placed narrow windows high in the walls to reduce bright sunlight. Egyptians often painted walls white to reflect the blazing heat. They wove sticks and palm trees to make roofs. Inside, woven reed mats covered the dirt floor. Most Egyptians slept on mats covered with linen sheets. Wealthy citizens enjoyed bed frames and cushions. Egyptian nobles had fancier homes with tree-lined courtyards for shade. Some had a pool filled with lotus blossoms and fish. Poorer Egyptians simply went to the roof to cool off after sunset. They often cooked, ate, and even slept outside. Egypt’s economy depended on farming. However, the natural resources of the area allowed other economic activities to develop too. The Egyptians wanted valuable metals that were not found in the black land. For example, they wanted copper to make tools and weapons. Egyptians looked for copper as early as 6000 B.C. Later they learned that iron was stronger, and they sought it as well. Ancient Egyptians also desired gold for its bright beauty. The Egyptian word for gold was nub. Nubia was the Egyptian name for the area of the upper Nile that had the richest gold mines in Africa. Mining minerals was difficult. Veins (long streaks) of copper, iron, and bronze were hidden inside desert mountains in the hot Sinai Peninsula, east of Egypt. Even during the cool season, chipping minerals out of the rock was miserable work. Egyptians mined precious stones too. They were probably the first people in the world to mine turquoise. The Egyptians also mined lapis lazuli. These beautiful blue stones were used in jewelry.The Nile had fish and other wildlife that Egyptians wanted. To go on the river, Egyptians made lightweight rafts by binding together reeds. They used everything from nets to harpoons to catch fish. One ancient painting even shows a man ready to hit a catfish with a wooden hammer. More adventurous hunters speared hippopotamuses and crocodiles along the Nile. Egyptians also captured quail with nets. They used boomerangs to knock down flying ducks and geese. (A boomerang is a curved stick that returns to the person who threw it.) Eventually, Egyptians equipped their reed boats with sails and oars. The Nile then became a highway. The river’s current was slow, so boaters used paddles to go faster when they traveled north with the current. Going south, they raised a sail and let the winds that blew in that direction push them. The Nile provided so well for Egyptians that sometimes they had surpluses, or more goods than they needed. They began to trade with each other. Ancient Egypt had no money, so people exchanged goods that they grew or made. This method of trade is called bartering. Egypt prospered along the Nile. This prosperity made life easier and provided greater opportunities for many Egyptians. When farmers produce food surpluses, the society’s economy begins to expand. Cities emerge as centers of culture and power, and people learn to do jobs that do not involve agriculture. For example, some ancient Egyptians learned to be scribes, people whose job was to write and keep records. As Egyptian civilization grew more complex, people took on jobs other than that of a farmer or scribe. Some skilled artisans erected stone or brick houses and temples. Other artisans made pottery, incense, mats, furniture, linen clothing, sandals, or jewelry. A few Egyptians traveled to the upper Nile to trade with other Africans. These traders took Egyptian products such as scrolls, linen, gold, and jewelry. They brought back exotic woods, animal skins, and live beasts. As Egypt grew, so did its need to organize. Egyptians created a government that divided the empire into 42 provinces. Many officials worked to keep the provinces running smoothly. Egypt also created an army to defend itself. One of the highest jobs in Egypt was to be a priest. Priests followed formal rituals and took care of the temples. Before entering a temple, a priest bathed and put on special linen garments and white sandals. Priests cleaned the sacred statues in temples, changed their clothes, and even fed them meals. Together, the priests and the ruler held ceremonies to please the gods. Egyptians believed that if the gods were angry, the Nile would not flood. As a result, crops would not grow, and people would die. So the ruler and the priests tried hard to keep the gods happy. By doing so, they hoped to maintain the social and political order. Slaves were at the bottom of society. In Egypt, people became slaves if they owed a debt, committed a crime, or were captured in war. Egyptian slaves were usually freed after a period of time. One exception was the slaves who had to work in the mines. Many died from the exhausting labor. Egypt was one of the best places in the ancient world to be a woman. Unlike other ancient African cultures, in Egyptian society men and women had fairly equal rights. For example, they could both own and manage their own property. The main job of most women was to care for their children and home, but some did other jobs too. Some women wove cloth. Others worked with their husbands in fields or workshops. Some women, such as Queen Tiy, even rose to important positions in the government. Children in Egypt played with toys such as dolls, animal figures, board games, and marbles. Their parents made the toys from wood or clay. Boys and girls also played rough physical games with balls made of leather or reeds. Boys and some girls from wealthy families went to schools run by scribes or priests. Most other children learned their parents’ jobs. Almost all Egyptians married when they were in their early teens. As in many ancient societies, much of the knowledge of Egypt came about as priests studied the world to find ways to please the gods. Other advances came about because of practical discoveries. Egyptian priests studied the sky as part of their religion. About 5,000 years ago, they noticed that a star now called Sirius appeared shortly before the Nile began to flood. The star returned to the same position in 365 days. Based on that, Egyptians developed the world’s first practical calendar. The Egyptians developed some of the first geometry. Each year the Nile’s floods washed away land boundaries. To restore property lines, surveyors measured the land by using ropes that were knotted at regular intervals. Geometric shapes such as squares and triangles were sacred to Egyptians. Architects used them in the design of royal temples and monuments. Egyptian doctors often prepared dead bodies for burial, so they knew the parts of the body. That knowledge helped them perform some of the world’s first surgery. Some doctors specialized in using medicines made of herbs. Egyptian medicine was far from perfect. Doctors believed that the heart controlled thought and the brain circulated blood, which is the opposite of what is known now. Some Egyptian treatments would raise eyebrows today. One “cure” for an upset stomach was to eat a hog’s tooth crushed inside sugar cakes! Beginning about 3000 B.C., Egyptians developed a writing system using hieroglyphs. Hieroglyphs Hieroglyphs are pictures that stand for different words or sounds. Early Egyptians created a hieroglyphic system with about 700 characters. Over time the system grew to include more than 6,000 symbols. The Egyptians also developed a paperlike material called papyrus papyrus from a reed of the same name. Egyptians cut the stems into strips, pressed them, and dried them into sheets that could be rolled into scrolls. Papyrus scrolls were light and easy to carry. With them, Egyptians created some of the first books. Legend says a king named Narmer united Upper and Lower Egypt. Some historians think Narmer actually represents several kings who gradually joined the two lands. After Egypt was united, its ruler wore the Double Crown. It combined the red Crown of Lower Egypt with the white Crown of Upper Egypt. The first dynasty of the Egyptian empire began about 2925 B.C. A dynasty is a line of rulers from the same family. When a king died, one of his children usually took his place as ruler. The order in which members of a royal family inherit a throne is called the succession. More than 30 dynasties ruled ancient Egypt. Historians divide ancient Egyptian dynasties into the Old Kingdom, the Middle Kingdom, and the New Kingdom. The Old Kingdom started about 2575 B.C., when the Egyptian empire was gaining strength. The king of Egypt became known as the pharaoh pharaoh. The word pharaoh meant “great house,” and it was originally used to describe the king’s palace. Later it became the title of the king himself. The pharaoh ruled from the capital city of Memphis. The ancient Egyptians thought the pharaoh was a child of the gods and a god himself. Egyptians believed that if the pharaoh and his subjects honored the gods, their lives would be happy. If Egypt suffered hard times for a long period, the people blamed the pharaoh for angering the gods. In such a case, a rival might drive him from power and start a new dynasty. Because the pharaoh was thought to be a god, government and religion were not separate in ancient Egypt. Priests had much power in the government. Many high officials were priests. The first rulers of Egypt were often buried in an underground tomb topped by mud brick. Soon, kings wanted more permanent monuments. They replaced the mud brick with a small pyramid of brick or stone. A pyramid is a structure shaped like a triangle, with four sides that meet at a point. About 2630 B.C., King Djoser built a much larger pyramid over his tomb. It is called a step pyramid because its sides rise in a series of giant steps. It is the oldest-known large stone structure in the world. About 80 years later, a pharaoh named Khufu decided he wanted a monument that would show the world how great he was. He ordered the construction of the largest pyramid ever built. Along its base, each side was about 760 feet long. The core was built from 2.3 million blocks of stone. Building the Great Pyramid was hard work. Miners cut the huge blocks of stone using copper saws and chisels. These tools were much softer than the iron tools developed later. Other teams of workers pulled the stone slabs up long, sloping ramps to their place on the pyramid. Near the top of the pyramid, the ramps ended. Workers dragged each heavy block hundreds of feet and then set it in place. Farmers did the heavy labor of hauling stone during the season when the Nile flooded their fields. Skilled stonecutters and overseers worked year-round. The Great Pyramid took nearly 20 years to build. An estimated 20,000 Egyptians worked on it. A city called Giza was built for the pyramid workers and the people who fed, clothed, and housed them. Eventually, Egyptians stopped building pyramids. One reason is that the pyramids drew attention to the tombs inside them. Grave robbers broke into the tombs to steal the treasure buried with the pharaohs. Sometimes they also stole the mummies. Egyptians believed that if a tomb was robbed, the person buried there could not have a happy afterlife. During the New Kingdom, pharaohs began building more secret tombs in an area called the Valley of the Kings. The burial chambers were hidden in mountains near the Nile. This way, the pharaohs hoped to protect their bodies and treasures from robbers. Both the pyramids and later tombs had several passageways leading to different rooms. This was to confuse grave robbers about which passage to take. Sometimes relatives, such as the queen, were buried in the extra rooms. Tombs were supposed to be the palaces of pharaohs in the afterlife. Mourners filled the tomb with objects ranging from food to furniture that the mummified pharaoh would need. Some tombs contained small statues that were supposed to be servants for the dead person. Egyptian artists decorated royal tombs with wall paintings and sculptures carved into the walls. Art was meant to glorify both the gods and the dead person. A sculpture of a dead pharaoh had “perfect” features, no matter how he really looked. Artists also followed strict rules about how to portray humans. Paintings showed a person’s head, arms, and legs from the side. They showed the front of the body from the neck down to the waist. Wall paintings showed pharaohs enjoying themselves so they could have a happy afterlife. One favorite scene was of the pharaoh fishing in a papyrus marsh. Warlike kings were often portrayed in battle. Scenes might also show people providing for the needs of the dead person. Such activities included growing and preparing food, caring for animals, and building boats. As hard as the pharaohs tried to hide themselves, robbers stole the treasures from almost every tomb. Only a secret tomb built for a New Kingdom pharaoh was ever found with much of its treasure untouched. The dazzling riches found in this tomb show how much wealth the pharaohs spent preparing for the afterlife. By about 2130 B.C., Egyptian kings began to lose their power to local rulers of the provinces. For about 500 more years, the kings held Egypt together, but with a much weaker central government. This period of Egyptian history is called the Middle Kingdom. Rulers during the Middle Kingdom also faced challenges from outside Egypt. A nomadic people called the Hyksos invaded Egypt from the northeast. Their army conquered by using better weapons and horse-drawn chariots, which were new to Egyptians. After about 100 years, the Egyptians drove out the Hyksos and began the New Kingdom.\""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "_YObCNXtr_J-",
        "GsHYe5BIpd1A",
        "mH2S209Id5Xx",
        "eoGYYFB1iym2",
        "2OvDVyWHuHSP",
        "D5_CNycnrcJf",
        "Pl5UsRdfrhJR",
        "CvsTz7g6rTQV"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}